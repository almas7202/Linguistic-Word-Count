{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fda5d99",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "878ac33d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enter a text : Years drift never if could forty being no. On estimable dependent as suffering on my. Rank it long have sure in room what as he. Possession travelling sufficient yet our. Talked vanity looked in to\n",
      "Number of words in the text: 35\n",
      "Verb count           :-  6\n",
      "Adverb count         :-  4\n",
      "Adjective count      :-  4\n",
      "Noun count           :-  6\n",
      "Pronoun count        :-  4\n",
      "Hashtag count        :-  0\n",
      "Number count         :-  0\n",
      "Special symbol count :-  0\n"
     ]
    }
   ],
   "source": [
    "# import neattext.functions as nfx\n",
    "import nltk\n",
    "\n",
    "# The re module in Python provides support for regular expressions (regex)\n",
    "# The module is used to perform various text operations, such as pattern matching, search and replace, and text parsing.\n",
    "import re\n",
    "\n",
    "# It devide the text/sentence into list of words.\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# import nfx\n",
    "import neattext.functions as nfx\n",
    "\n",
    "# text_data='On recommend tolerably my belonging or am. Mutual has cannot beauty indeed now sussex merely you'\n",
    "text_data=input(\"Enter a text : \")\n",
    "\n",
    "text_data = nfx.remove_punctuations(text_data)\n",
    "# print(clean_text)\n",
    "\n",
    "text_data=nfx.remove_multiple_spaces(text_data)\n",
    "\n",
    "\n",
    "text_data=nfx.remove_puncts(text_data)\n",
    "\n",
    "# tokenize the text string into words\n",
    "words = word_tokenize(text_data)\n",
    "\n",
    "# Word for Hashtag\n",
    "wd = text_data.split(\" \")\n",
    "\n",
    "# It is used to assigning a part of speech tag (noun, verb, adjective, adverb, etc.) to each word in a text.\n",
    "pos_tags = nltk.pos_tag(words)\n",
    "\n",
    "# initialize counts for each part of speech\n",
    "verb_count = 0\n",
    "adverb_count = 0\n",
    "adjective_count = 0\n",
    "noun_count = 0\n",
    "pronoun_count = 0\n",
    "hashtag_count = 0\n",
    "number_count = 0\n",
    "special_count = 0\n",
    "\n",
    "# List of all Functionality.\n",
    "verbs = []\n",
    "adverbs = []\n",
    "adjectives = []\n",
    "nouns = []\n",
    "pronouns = []\n",
    "hashtags = []\n",
    "special_simbols = []\n",
    "\n",
    "# loop through the tagged words and count the instances of each part of speech and hashtags\n",
    "for word,pos in pos_tags:\n",
    "    if pos.startswith('V'):  # verbs (VBP)\n",
    "        verb_count += 1\n",
    "        verbs.append(word)\n",
    "        \n",
    "    elif pos.startswith('RB'):  # adverbs(RB)\n",
    "        adverb_count += 1\n",
    "        adverbs.append(word)\n",
    "        \n",
    "    elif pos.startswith('JJ'):  # adjectives (JJ)\n",
    "        adjective_count += 1\n",
    "        adjectives.append(word)\n",
    "        \n",
    "    elif pos.startswith('N'):  # nouns (NN)\n",
    "        noun_count += 1\n",
    "        nouns.append(word)\n",
    "        \n",
    "    elif pos.startswith('PR'):  # pronouns (PRP)\n",
    "        pronoun_count += 1\n",
    "        pronouns.append(word)\n",
    "        \n",
    "    #circumflex means not,\\s means matches any whitespace character (i.e., space, tab, newline, etc\n",
    "    elif re.match('[^a-zA-Z0-9\\s]+', word):  # special symbols\n",
    "        special_count += 1\n",
    "        special_simbols.append(word)\n",
    "\n",
    "\n",
    "# hashtags    \n",
    "for word in wd:\n",
    "    if word.startswith('#'):  # hashtags\n",
    "        hashtag_count += 1\n",
    "        hashtags.append(word)\n",
    "        \n",
    "# Numbers\n",
    "import re\n",
    "numbers = re.findall(r'\\d+',text_data)\n",
    "number_count = len(numbers)\n",
    "\n",
    "count = len(text_data.split())\n",
    "print(\"Number of words in the text:\", count)\n",
    "\n",
    "        \n",
    "# # print the counts for each part of speech and hashtags\n",
    "print('Verb count           :- ', verb_count)\n",
    "print('Adverb count         :- ', adverb_count)\n",
    "print('Adjective count      :- ', adjective_count)\n",
    "print('Noun count           :- ', noun_count)\n",
    "print('Pronoun count        :- ', pronoun_count)\n",
    "print('Hashtag count        :- ', hashtag_count)\n",
    "\n",
    "print('Number count         :- ', number_count)\n",
    "print('Special symbol count :- ', special_count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7ff6ed0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['forty', 'being', 'suffering', 'have', 'travelling', 'looked']\n"
     ]
    }
   ],
   "source": [
    "print(verbs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "e183f55d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['drift', 'never', 'long', 'yet']\n"
     ]
    }
   ],
   "source": [
    "print(adverbs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3a42e00d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Years', 'dependent', 'Rank', 'room', 'Possession', 'vanity']\n"
     ]
    }
   ],
   "source": [
    "print(nouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "1fe394fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['my', 'it', 'he', 'our']\n"
     ]
    }
   ],
   "source": [
    "print(pronouns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d4e80860",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n"
     ]
    }
   ],
   "source": [
    "print(hashtags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c7ce274",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
